{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Abstract Generator Model",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yRN30hAWKGQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1cd69c9-6238-49c2-a32a-bd806e44e60a"
      },
      "source": [
        "# tqdm version 4.36.1 is required\n",
        "!pip install tqdm==4.36.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm==4.36.1 in /usr/local/lib/python3.6/dist-packages (4.36.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxlIcG9tWV1Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ac8d081-4fe5-45a7-bdd0-7d7a418ea437"
      },
      "source": [
        "# Mounting Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulS4VyTQUe92",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "039aac68-8d2e-4aea-8b47-70af2d719a8c"
      },
      "source": [
        "!pip install keras==2.2.4"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.18.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeYeuULxWb4Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6cba9a26-78ef-48b5-cfc8-0da2974670ea"
      },
      "source": [
        "import numpy as np  \n",
        "import pandas as pd \n",
        "import re           \n",
        "import glob\n",
        "from bs4 import BeautifulSoup \n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords   \n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import load_model\n",
        "import keras\n",
        "import warnings\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkenhppLWg-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Progress bar\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M25zNardWsRI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f33c3679-5515-442e-d209-db6e57edadc1"
      },
      "source": [
        "# Load Data\n",
        "data = pd.read_csv('/content/drive/My Drive/MyPreProcessedDataset.csv')\n",
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>MAIN-TITLE</th>\n",
              "      <th>HIGHLIGHTS</th>\n",
              "      <th>KEYPHRASES</th>\n",
              "      <th>ABSTRACT</th>\n",
              "      <th>ACKNOWLEDGEMENTS</th>\n",
              "      <th>REFERENCES</th>\n",
              "      <th>INTRODUCTION</th>\n",
              "      <th>RELATED WORK</th>\n",
              "      <th>OVERVIEW</th>\n",
              "      <th>IMPLEMENTATION</th>\n",
              "      <th>METHOD</th>\n",
              "      <th>MOTIVATION</th>\n",
              "      <th>LIMITATIONS</th>\n",
              "      <th>RESULT | CONCLUSION | DISCUSSION</th>\n",
              "      <th>BODY</th>\n",
              "      <th>Body_LENGTH</th>\n",
              "      <th>cleaned_highlights</th>\n",
              "      <th>cleaned_body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>197</td>\n",
              "      <td>\\n</td>\n",
              "      <td>\\n\\n               \\n               \\n                  \\n                     \\n                        \\n                           \\n                           The aggregated artificial neural ...</td>\n",
              "      <td>\\nScaffolds\\n\\n3D printer\\n\\nAggregated artificial neural network (AANN)\\n\\nParticle swarm optimization (PSO)\\n\\nPorous structure\\n\\nMechanical strength\\n\\n</td>\n",
              "      <td>\\n\\n               \\n               \\n                  Fabrication of three-dimensional structures has gained increasing importance in the bone tissue engineering (BTE) field. Mechanical properti...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>\\nAdditive manufacturing (AM) is a layer-over-layer manufacturing technique. In most cases, enables complex components to be manufactured that are difficult to fabricate or cannot be made using co...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>\\nIn this section, a predictive model for 3DP process is extracted. The model predicts the mechanical strength, and the open porosity of a part fabricated using this process. Mechanical strength a...</td>\n",
              "      <td>\\nAdditive manufacturing (AM) is a layer-over-layer manufacturing technique. In most cases, enables complex components to be manufactured that are difficult to fabricate or cannot be made using co...</td>\n",
              "      <td>76648</td>\n",
              "      <td>_START_ fabrication of threedimensional structures has gained increasing importance in the bone tissue engineering bte field. mechanical properties and permeability are two important requirement f...</td>\n",
              "      <td>additive manufacturing layeroverlayer manufacturing technique. cases enables complex components manufactured difficult fabricate conventional methods. practices powderbased threedimensional printi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>220</td>\n",
              "      <td>\\n</td>\n",
              "      <td>\\n\\n               \\n                  \\n                  \\n                     \\n                        \\n                           \\n                           A stochastic global optimizati...</td>\n",
              "      <td>\\nOpen pit mine design\\n\\nGlobal optimization\\n\\nProduction scheduling\\n\\nMetaheuristics\\n\\nDestination policy\\n\\n</td>\n",
              "      <td>\\n\\n               \\n               \\n                  Global optimization for mining complexes aims to generate a production schedule for the various mines and processing streams that maximizes ...</td>\n",
              "      <td>\\nThe work in this paper was funded by NSERC CRD 411270, NSERC Discovery Grant 239019, and the industry members of the COSMO Stochastic Mine Planning Laboratory: AngloGold Ashanti, Barrick Gold, B...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>\\nGlobal optimization for mining complexes addresses the issue of integrated mining and processing operations with multiple pits or underground mines, multiple metals or minerals, stockpiles, blen...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>\\nThis work presents a framework for global asset optimization of mining complexes under uncertainty, whereby the solutions provide robust long-term open-pit mine extraction sequences and destinat...</td>\n",
              "      <td>\\nGlobal optimization for mining complexes addresses the issue of integrated mining and processing operations with multiple pits or underground mines, multiple metals or minerals, stockpiles, blen...</td>\n",
              "      <td>158323</td>\n",
              "      <td>_START_ global optimization for mining complexes aims to generate a production schedule for the various mines and processing streams that maximizes the economic value of the enterprise as a whole....</td>\n",
              "      <td>global optimization mining complexes addresses issue integrated mining processing operations multiple pits underground mines multiple metals minerals stockpiles blending options alternative proces...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>287</td>\n",
              "      <td>\\n</td>\n",
              "      <td>\\n\\n               \\n                  \\n                  \\n                     \\n                        \\n                           \\n                           High-dimensional biological da...</td>\n",
              "      <td>\\nFuzzy systems\\n\\nSupport vector regression\\n\\nPeptide binding affinity\\n\\n</td>\n",
              "      <td>\\n\\n               \\n               \\n                  Support vector machines have a wide use for the prediction problems in life sciences. It has been shown to offer more generalisation ability...</td>\n",
              "      <td>\\nDuring this study, Volkan Uslan was funded by De Montfort University Leicester with full PhD tuition fee scholarship. The authors thank to Dr Ovidiu Ivanciuc for organising the CoEPrA contest th...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>\\nPeptide binding plays vital roles in the molecular biology of the cell. The process of the peptide binding can activate the cytotoxic T-cells in the immune system [1]. One of the most challengin...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>\\nIn this paper, a hybrid system (TSK-SVR) that has helped improve the predictive ability of TSK-FS significantly with the aid of support-based vector method was developed and demonstrated with th...</td>\n",
              "      <td>\\nPeptide binding plays vital roles in the molecular biology of the cell. The process of the peptide binding can activate the cytotoxic T-cells in the immune system [1]. One of the most challengin...</td>\n",
              "      <td>58869</td>\n",
              "      <td>_START_ support vector machines have a wide use for the prediction problems in life sciences. it has been shown to offer more generalisation ability in inputoutput mapping. however the performance...</td>\n",
              "      <td>peptide binding plays vital roles molecular biology cell. process peptide binding activate cytotoxic tcells immune system challenging complex aspect peptide binding prediction proteinpeptide bindi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>298</td>\n",
              "      <td>\\n</td>\n",
              "      <td>\\n\\n               \\n                  \\n                  \\n                     \\n                        \\n                           \\n                           Few graph layout methods captu...</td>\n",
              "      <td>\\nSmall world networks\\n\\nAdjacency matrix\\n\\nNode attributes\\n\\nGraph visualization\\n\\nTargeted projection pursuit\\n\\n</td>\n",
              "      <td>\\n\\n               \\n               \\n                  Many networks exhibit small-world properties. The structure of a small-world network is characterized by short average path lengths and high...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>\\nSmall-world networks are a commonly occurring graph structure characterized by short average path lengths and high clustering coefficients [1]. This means that even when the network is large the...</td>\n",
              "      <td>\\nSmall-world networks are characterized by short average path lengths (the shortest path between any pair of nodes) and high clustering coefficients (e.g., in social networks this would be the nu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>\\nThis paper has presented an extension to the small-worlds pilot study presented in Gibson and Faith [8] where graphTPP was used to lay out a small-world network using node attributes. In this ca...</td>\n",
              "      <td>\\nSmall-world networks are a commonly occurring graph structure characterized by short average path lengths and high clustering coefficients [1]. This means that even when the network is large the...</td>\n",
              "      <td>37747</td>\n",
              "      <td>_START_ many networks exhibit smallworld properties. the structure of a smallworld network is characterized by short average path lengths and high clustering coefficients. few graph layout methods...</td>\n",
              "      <td>smallworld networks commonly occurring graph structure characterized short average path lengths high clustering coefficients means network large steps pair nodes. despite prevalence methods able l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>396</td>\n",
              "      <td>\\n</td>\n",
              "      <td>\\n\\n               \\n               \\n                  \\n                     \\n                        \\n                           \\n                           Cost of simulation in the cloud c...</td>\n",
              "      <td>\\nCloud based simulation\\n\\nSimulation of the cloud\\n\\nCost optimization\\n\\nAmazon EC2\\n\\nSpot prices\\n\\n</td>\n",
              "      <td>\\n\\n               \\n               \\n                  Large scale simulations require considerable amounts of computing power and often cloud services are utilized to perform them. In such setti...</td>\n",
              "      <td>\\nWe would like to thank the three anonymous reviewers for their insightful comments that helped us to improve the article.\\n\\n</td>\n",
              "      <td>NaN</td>\n",
              "      <td>\\nThe goal of this paper is to propose an algorithm for a cost and time optimization for running simulations on public computational clusters with a spot pricing mechanism. The algorithm is implem...</td>\n",
              "      <td>\\nThe cloud computing paradigm (Infrastructure as a Service) is gaining increasing popularity due to highly competitive costs compared to employing on-site infrastructure. With Amazon currently be...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>\\nThe goal of this paper is to propose an algorithm for a cost and time optimization for running simulations on public computational clusters with a spot pricing mechanism. The algorithm is implem...</td>\n",
              "      <td>77455</td>\n",
              "      <td>_START_ large scale simulations require considerable amounts of computing power and often cloud services are utilized to perform them. in such settings the execution costs can be significantly dec...</td>\n",
              "      <td>goal paper propose algorithm cost time optimization running simulations public computational clusters spot pricing mechanism. algorithm implemented python ready application reallife computationall...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                                                                                                                                                                             cleaned_body\n",
              "0         197  ...  additive manufacturing layeroverlayer manufacturing technique. cases enables complex components manufactured difficult fabricate conventional methods. practices powderbased threedimensional printi...\n",
              "1         220  ...  global optimization mining complexes addresses issue integrated mining processing operations multiple pits underground mines multiple metals minerals stockpiles blending options alternative proces...\n",
              "2         287  ...  peptide binding plays vital roles molecular biology cell. process peptide binding activate cytotoxic tcells immune system challenging complex aspect peptide binding prediction proteinpeptide bindi...\n",
              "3         298  ...  smallworld networks commonly occurring graph structure characterized short average path lengths high clustering coefficients means network large steps pair nodes. despite prevalence methods able l...\n",
              "4         396  ...  goal paper propose algorithm cost time optimization running simulations public computational clusters spot pricing mechanism. algorithm implemented python ready application reallife computationall...\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfQR9pLNXKZz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "5045ef25-ed0c-4b18-9e89-cabd228b1ec2"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8022 entries, 0 to 8021\n",
            "Data columns (total 19 columns):\n",
            " #   Column                            Non-Null Count  Dtype \n",
            "---  ------                            --------------  ----- \n",
            " 0   Unnamed: 0                        8022 non-null   int64 \n",
            " 1   MAIN-TITLE                        8022 non-null   object\n",
            " 2   HIGHLIGHTS                        8022 non-null   object\n",
            " 3   KEYPHRASES                        8022 non-null   object\n",
            " 4   ABSTRACT                          8022 non-null   object\n",
            " 5   ACKNOWLEDGEMENTS                  5158 non-null   object\n",
            " 6   REFERENCES                        1 non-null      object\n",
            " 7   INTRODUCTION                      7942 non-null   object\n",
            " 8   RELATED WORK                      2188 non-null   object\n",
            " 9   OVERVIEW                          137 non-null    object\n",
            " 10  IMPLEMENTATION                    413 non-null    object\n",
            " 11  METHOD                            1686 non-null   object\n",
            " 12  MOTIVATION                        113 non-null    object\n",
            " 13  LIMITATIONS                       216 non-null    object\n",
            " 14  RESULT | CONCLUSION | DISCUSSION  7072 non-null   object\n",
            " 15  BODY                              8022 non-null   object\n",
            " 16  Body_LENGTH                       8022 non-null   int64 \n",
            " 17  cleaned_highlights                8022 non-null   object\n",
            " 18  cleaned_body                      8022 non-null   object\n",
            "dtypes: int64(2), object(17)\n",
            "memory usage: 1.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zph3L3GQXPFq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "705fce60-d82b-4ada-8713-6286a0264e5c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "for i in data['cleaned_body']:\n",
        "      text_word_count.append(len(i.split()))\n",
        "\n",
        "for i in data['cleaned_highlights']:\n",
        "      summary_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'Content':text_word_count, 'Abstract':summary_word_count})\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df7RVZb3v8fcnUfNaCojtgUhhJ7KDOSTdqY3Mu0+UIjbC7igPHm+ScaNGeMob3YLqXj2aHapLllZ2MDlCFyXSDG5Stg+5jqd7QgUjEc3LBvECIZTgj61lYd/7x3w2TpZrsdeGtdcP5uc1xhp7zmc+c67vs/dc3/U8z5xrL0UEZmZWDK9odgBmZtY4TvpmZgXipG9mViBO+mZmBeKkb2ZWIE76ZmYF4qTfRJJulvTFZsdhZsXhpN8gkkqSdkk6vA7HGtQ3C0mbJL1rsI5vxSHp7yStktQraZukn0g66wCPWdfzv2jnu5N+A0gaA7wDCOC9DXi+IYP9HGb9kfQp4OvAl4AO4LXAt4HJzYyr8CLCj0F+AP8D+D/A14Af58pvBr4DdAPPAv8KvC5tE3AtsAN4BlgLvBmYDvwZ+BPQC/zvVH8T8FngQeAFYAgwC9iQjv0w8L6yuD4CPJLbfirwPeAvwB/S8T/T7N+fH+33AI5O588Hqmw/nOwN4bfp8XXg8LStC9gCzEzn/zbg0rSt2vl/HHA78DvgMeATuee6ElgCLEzn+jqgM20r3Pne9ACK8AB6gI8Dp6UTtiOV35xOwrPTi+AbwC/StnOB1cDQ9Abw18DI3H5fLHuOTcAaYDRwRCr7QHoxvAL4W+C53DE+AGwF3pqO/4bcG84m4F3N/r350b4PYCKwGxhSZftVwErgNcCxwL8DV6dtXWnfq4BDgUnA88CwtH2v8z+d36vJOleHAa8HNgLnpu1XAn9MxzkE+EdgZW7/Qp3vnt4ZZGn+8nXAkohYTdbz/rtclTsj4p6IeAH4PPA2SaPJ3hxeDbwJUEQ8EhHb+nm66yJic0T8ASAifhARv42Iv0TE94H1wOmp7n8BvhIR90emJyIer1e7rfCOAX4fEburbL8YuCoidkTE74B/AD6Y2/7ntP3PEbGcrBd+YpVjvRU4NiKuiog/RcRG4EZgSq7OLyJieUS8SNa7P2X/m9benPQH31TgZxHx+7R+Syrrs7lvISJ6gZ3AcRHxc+CbwLeAHZLmSTqqn+fanF+RdImkNZKekvQU2fTQiLR5NNkbkNlgeBIYsY/rS8cB+U7G46lsz/5lbxjPA6+qcqzXAcf1nefpXP8c2XWEPk+UHeuVRb32VchGN4qkI4ALgUMk9Z10hwNDJfX1NEbn6r8KGE42x0lEXAdcJ+k1ZHOS/w3472QXhCvZUy7pdWS9nQnALyPiRUlryKZyIHuD+Kv+jmO2n35Jdm3pAuC2Ctt/S5as16X116ayWpSfn5uBxyJi7H7EWel4BzX39AfXBcCLwDhgfHr8NfBvwCWpziRJZ0k6DLiabK5xs6S3SjpD0qFkc/F/JLvgBLCdbN5yX44kO5l/ByDpUrKefp/vAp+WdJoyb0hvFLUe36yqiHiabI79W5IukPQfJB0q6TxJXwFuBb4g6VhJI1Ld/1Xj4cvPz/uAZyV9VtIRkg6R9GZJb93P4x3UnPQH11TgnyPi/0XEE30Psmmbi8lGWrcAV5BN65wG/Oe071FkPfVdZEPfJ4Gvpm03AePSUPZHlZ44Ih4G5pL1uLYDJ5PdQdS3/QfANen5nwV+RDbKgOxC1xfS8T99wL8FK6SImAt8CvgCWedjM3AZ2bn2RWAV2d1ma4EHUlkt9jr/0zz9e8g6VY8Bvyfr1Bxd4/EKdb4rXb02M7MCcE/fzKxAnPTNzArESd/MrECc9M3MCqSl79MfMWJEjBkzpuK25557jiOPPLKxAR0Axzv4qsW8evXq30fEsU0Iab9UO+/b8W9Si4OxXc1u0z7P+Wb/H4h9PU477bSo5u677666rRU53sFXLWZgVbTA+Vzro9p5345/k1ocjO1qdpv2dc57esfMrECc9M3MCsRJ38ysQJz0zcwKxEnfzKxAnPTNzAqk36Qv6cT0RRx9j2ckXS5puKRuSevTz2GpviRdJ6lH0oOSTs0da2qqv17S1OrPamZmg6HfpB8Rj0bE+IgYT/avf58H7iD70u0VkX1xwYq0DnAeMDY9pgM3AEgaTvYvhM8g+8q+K/reKMzMrDEGOr0zAdgQ2XepTgYWpPIFZF8YQipfmD4jsJLsW6JGkn3Rd3dE7IyIXUA32Zcnm7UUSfMl7ZD0UK7s+7nR7qb0LWRIGiPpD7lt38ntc5qktWnUe50kVXo+s0Ya6L9hmEL2jTcAHfHSF3U/wUvfRzmKvb+rdUsqq1a+F0nTyUYIdHR0UCqVKgayY+fTXL9o6Z71k0fV+n0JzdHb21u1La2o3eKFusZ8M9kX3SzsK4iIv+1bljQXeDpXf0MaCZe7AfgIcC+wnKyT85N6BFjNmFl37rW+ac75g/l01oZqTvrp6/zeC8wu3xYRIaku38YSEfOAeQCdnZ3R1dVVsd71i5Yyd+1L4W+6uHK9VlEqlajWllbUbvFC/WKOiHskjam0LfXWLwTeua9jpNHtUWm0i6SFZKPhQU36Zv0ZyPTOecADEbE9rW9PJ3bfCb4jlW8l92XfwPGprFq5WTt5B7A9Itbnyk6Q9CtJ/yrpHalsFNlotk/Fka1Zow1keuciXpraAVhG9h2wc9LPpbnyyyQtJrto+3REbJN0F/Cl3MXbc6gwajBrceWvg23AayPiSUmnAT+SdNJAD1rLtGYt01czT96913o7TNG141Rif1q5TTUlfUlHAu8GPporngMskTSN7Iu7L0zly4FJQA/ZnT6XAkTETklXA/eneldFxM4DboFZg0gaAvwnsrvYAIiIF4AX0vJqSRuAN5KNYo/P7b7PkW0t05q1TF99qHxOv8WnPaE9pxL708ptqinpR8RzwDFlZU+S3c1TXjeAGVWOMx+YP/AwzVrCu4DfRMSeaRtJxwI7I+JFSa8nu1V5Y+rkPCPpTLILuZcA1zclarMcfyLXrIykW4FfAidK2pJGs7D33Wt9zgYeTLdw3gZ8LDeC/TjwXbJR7wZ8EddaQEt/c5ZZM0TERVXKP1Sh7Hbg9ir1VwFvrmtwZgfIPX0zswJx0jczKxAnfTOzAvGcvlkbK/+3C2b9cU/fzKxAnPTNzArESd/MrECc9M3MCsRJ38ysQJz0zcwKxEnfzKxAnPTNzArESd/MrECc9M3MCsRJ38ysQJz0zcwKxEnfzKxAnPTNzAqkpqQvaaik2yT9RtIjkt4mabikbknr089hqa4kXSepR9KDkk7NHWdqqr9e0tTBapSZmVVWa0//G8BPI+JNwCnAI8AsYEVEjAVWpHWA84Cx6TEduAFA0nDgCuAM4HTgir43CjMza4x+k76ko4GzgZsAIuJPEfEUMBlYkKotAC5Iy5OBhZFZCQyVNBI4F+iOiJ0RsQvoBibWtTVmZrZPtXxz1gnA74B/lnQKsBr4JNAREdtSnSeAjrQ8Ctic239LKqtWvhdJ08lGCHR0dFAqlSoG1XEEzDx59571avVaRW9vb8vHmNdu8UL9YpY0H3gPsCMi3pzKrgQ+QvZaAPhcRCxP22YD04AXgU9ExF2pfCLZKPkQ4LsRMeeAgzM7QLUk/SHAqcDfR8S9kr7BS1M5AERESIp6BBQR84B5AJ2dndHV1VWx3vWLljJ37Uvhb7q4cr1WUSqVqNaWVtRu8UJdY74Z+CawsKz82oj4n/kCSeOAKcBJwHHAv0h6Y9r8LeDdZB2c+yUti4iH6xGg2f6qJelvAbZExL1p/TaypL9d0siI2Jamb3ak7VuB0bn9j09lW4GusvLS/oduNjgi4h5JY2qsPhlYHBEvAI9J6iG7ZgXQExEbASQtTnUbmvQrfYfupjnnNzIEazH9Jv2IeELSZkknRsSjwASyE/dhYCowJ/1cmnZZBlyWTvIzgKfTG8NdwJdyF2/PAWbXtzlmg+oySZcAq4CZ6drUKGBlrk5+2rJ8OvOMageuZVqz0vRVfoqzVq02bdeOU4n9aeU21dLTB/h7YJGkw4CNwKVkF4GXSJoGPA5cmOouByYBPcDzqS4RsVPS1cD9qd5VEbGzLq0wG3w3AFcDkX7OBT5cr4PXMq15/aKlzP3Fc2Wltb6EX9JqU6HtOJXYn1ZuU01nTESsATorbJpQoW4AM6ocZz4wfyABmrWCiNjetyzpRuDHabXadCb7KDdrGn8i16wG6bpVn/cBD6XlZcAUSYdLOoHs8yn3kY1ox0o6IY2Qp6S6Zk018LGh2UFO0q1kNx2MkLSF7EOFXZLGk03vbAI+ChAR6yQtIbvGtRuYEREvpuNcBtxFdsvm/IhY1+CmmL2Mk75ZmYi4qELxTfuofw1wTYXy5WTXuMxahqd3zMwKxEnfzKxAnPTNzArESd/MrECc9M3MCsRJ38ysQJz0zcwKxEnfzKxAnPTNzArESd/MrECc9M3MCsRJ38ysQJz0zcwKxEnfzKxAnPTNzArESd/MrECc9M3MCsRJ38ysQGpK+pI2SVoraY2kValsuKRuSevTz2GpXJKuk9Qj6UFJp+aOMzXVXy9p6uA0yczMqhlIT/9vImJ8RHSm9VnAiogYC6xI6wDnAWPTYzpwA2RvEmRfMH0GcDpwRd8bhZmZNcaBTO9MBhak5QXABbnyhZFZCQyVNBI4F+iOiJ0RsQvoBiYewPObDQpJ8yXtkPRQruyrkn6TRq93SBqaysdI+kMaBa+R9J3cPqelEXJPGv2qGe0xyxtSY70AfiYpgH+KiHlAR0RsS9ufADrS8ihgc27fLamsWvleJE0nGyHQ0dFBqVSqGFDHETDz5N171qvVaxW9vb0tH2Neu8ULdY35ZuCbwMJcWTcwOyJ2S/oyMBv4bNq2ISLGVzjODcBHgHuB5WSdnJ/UI0Cz/VVr0j8rIrZKeg3QLek3+Y0REekN4YClN5R5AJ2dndHV1VWx3vWLljJ37Uvhb7q4cr1WUSqVqNaWVtRu8UL9Yo6IeySNKSv7WW51JfD+fR0jjW6PSqNdJC0kGw076VtT1ZT0I2Jr+rlD0h1kc/LbJY2MiG3pBN+Rqm8FRud2Pz6VbQW6yspLBxS9WXN8GPh+bv0ESb8CngG+EBH/RjaK3ZKrU3Fk26eWEW756HZ/tdoIrh1Hlf1p5Tb1m/QlHQm8IiKeTcvnAFcBy4CpwJz0c2naZRlwmaTFZBdtn05vDHcBX8pdvD2HbIhs1jYkfR7YDSxKRduA10bEk5JOA34k6aSBHreWEW756HZ/tdqouB1Hlf1p5TbVcgZ1AHeka1BDgFsi4qeS7geWSJoGPA5cmOovByYBPcDzwKUAEbFT0tXA/aneVRGxs24tMRtkkj4EvAeYEBEBEBEvAC+k5dWSNgBvJBvZHp/bvW/Ea9ZU/Sb9iNgInFKh/ElgQoXyAGZUOdZ8YP7AwzRrLkkTgc8A/zEins+VHwvsjIgXJb2e7FbljamT84ykM8ku5F4CXN+M2M3yDnysaHaQkXQr2fWnEZK2kH2+ZDZwONmNDAArI+JjwNnAVZL+DPwF+FhuBPtxsjuBjiC7gOuLuNZ0TvpmZSLiogrFN1Wpeztwe5Vtq4A31zE0swPm/71jZlYgTvpmZgXipG9mViBO+mZmBeKkb2ZWIE76ZmYF4qRvZlYgTvpmZgXipG9mViBO+mZmBeKkb2ZWIE76ZmYF4qRvZlYgTvpmZgXipG9mViBO+mZmBeKkb2ZWIE76ZmYFUnPSl3SIpF9J+nFaP0HSvZJ6JH1f0mGp/PC03pO2j8kdY3Yqf1TSufVujJmZ7dtAevqfBB7JrX8ZuDYi3gDsAqal8mnArlR+baqHpHHAFOAkYCLwbUmHHFj4ZmY2EDUlfUnHA+cD303rAt4J3JaqLAAuSMuT0zpp+4RUfzKwOCJeiIjHgB7g9Ho0wqzeJM2XtEPSQ7my4ZK6Ja1PP4elckm6Lo1iH5R0am6fqan+eklTm9EWs7whNdb7OvAZ4NVp/RjgqYjYnda3AKPS8ihgM0BE7Jb0dKo/CliZO2Z+nz0kTQemA3R0dFAqlSoG1HEEzDx59571avVaRW9vb8vHmNdu8ULdY74Z+CawMFc2C1gREXMkzUrrnwXOA8amxxnADcAZkoYDVwCdQACrJS2LiF31CtJsoPpN+pLeA+yIiNWSugY7oIiYB8wD6OzsjK6uyk95/aKlzF37UvibLh700A5IqVSiWltaUbvFC/WNOSLuyV+PSiYDfU+wACiRJf3JwMKICGClpKGSRqa63RGxE0BSN9nU5q11CdJsP9TS03878F5Jk4BXAkcB3wCGShqSevvHA1tT/a3AaGCLpCHA0cCTufI++X3M2kFHRGxLy08AHWl5z+g26RvFVit/mVpGuOWj2/3VaiO4dhxV9qeV29Rv0o+I2cBsgNTT/3REXCzpB8D7gcXAVGBp2mVZWv9l2v7ziAhJy4BbJH0NOI5sKHxffZtj1hjpnI46Hq/fEW756HZ/tdqouB1Hlf1p5TYdyH36nwU+JamHbM7+plR+E3BMKv8U2bwnEbEOWAI8DPwUmBERLx7A85s12vY0bUP6uSOVVxvFenRrLWdA3YaIKJHNYxIRG6lw901E/BH4QJX9rwGuGWiQZi2ibxQ7h5ePbi+TtJjsQu7TEbFN0l3Al/ru8gHOIY2azZrlwMeKZgchSbeSXYgdIWkL2V04c4AlkqYBjwMXpurLgUlktyE/D1wKEBE7JV0N3J/qXdV3UdesWZz0zSqIiIuqbJpQoW4AM6ocZz4wv46hmR0Q/+8dM7MCcdI3MysQJ30zswJx0jczKxAnfTOzAnHSNzMrECd9M7MCcdI3MysQJ30zswJx0jczKxAnfTOzAnHSNzMrEP/DNbOCGTPrzr3WN805v0mRWDO4p29mViBO+mZmBeKkb2ZWIE76ZmYF4qRvZlYgTvpmZgXSb9KX9EpJ90n6taR1kv4hlZ8g6V5JPZK+L+mwVH54Wu9J28fkjjU7lT8q6dzBapSZmVVWS0//BeCdEXEKMB6YKOlM4MvAtRHxBmAXMC3VnwbsSuXXpnpIGgdMAU4CJgLflnRIPRtjNpgknShpTe7xjKTLJV0paWuufFJuH3d0rKX0m/Qj05tWD02PAN4J3JbKFwAXpOXJaZ20fYIkpfLFEfFCRDwG9ACn16UVZg0QEY9GxPiIGA+cBjwP3JE2X9u3LSKWgzs61ppq+kRuOlFXA28AvgVsAJ6KiN2pyhZgVFoeBWwGiIjdkp4GjknlK3OHze+Tf67pwHSAjo4OSqVSxZg6joCZJ+/es16tXqvo7e1t+Rjz2i1eaHjME4ANEfF41qepaE9HB3hMUl9H55cNitHsZWpK+hHxIjBe0lCyns2bBiugiJgHzAPo7OyMrq6uivWuX7SUuWtfCn/TxZXrtYpSqUS1trSidosXGh7zFODW3Pplki4BVgEzI2IXNXZ0oLbOTnlHp16a/ebejh2M/rRymwb0v3ci4ilJdwNvA4ZKGpJ6+8cDW1O1rcBoYIukIcDRwJO58j75fczaRrpp4b3A7FR0A3A12bTn1cBc4MMDOWYtnZ3yjk69NLvD1I4djP60cptquXvn2NTDR9IRwLuBR4C7gfenalOBpWl5WVonbf95REQqn5Lu7jkBGAvcV6+GmDXQecADEbEdICK2R8SLEfEX4EZeulbljo61nFq6DSOBBWle/xXAkoj4saSHgcWSvgj8Crgp1b8J+F6av9xJNgwmItZJWgI8DOwGZqRpI7N2cxG5qR1JIyNiW1p9H/BQWl4G3CLpa8BxuKNjLaDfpB8RDwJvqVC+kQp330TEH4EPVDnWNcA1Aw/TrDVIOpJstPvRXPFXJI0nm97Z1LfNHR1rRf5/+mYDEBHPkd2Nli/74D7qu6NjLcX/hsHMrECc9M3MCsRJ38ysQJz0zcwKxEnfzKxAnPTNzArESd/MrECc9M3MCsRJ38ysQJz0zcwKxEnfzKxAnPTNzArESd/MrECc9M3MCsRJ38ysQJz0zcwKxEnfzKxAnPTNzArESd/MrED6TfqSRku6W9LDktZJ+mQqHy6pW9L69HNYKpek6yT1SHpQ0qm5Y01N9ddLmjp4zTIzs0pq6envBmZGxDjgTGCGpHHALGBFRIwFVqR1gPOAsekxHbgBsjcJ4ArgDOB04Iq+NwqzdiFpk6S1ktZIWpXKBtwBMmuWfpN+RGyLiAfS8rPAI8AoYDKwIFVbAFyQlicDCyOzEhgqaSRwLtAdETsjYhfQDUysa2vMGuNvImJ8RHSm9QF1gMyaaUBz+pLGAG8B7gU6ImJb2vQE0JGWRwGbc7ttSWXVys3a3UA7QGZNM6TWipJeBdwOXB4Rz0jasy0iQlLUIyBJ08l6RXR0dFAqlSrW6zgCZp68e896tXqtore3t+VjzGu3eKFhMQfws3S+/1NEzGPgHaBtlKnlvC8/5+ul2X/ndjzX+tPKbaop6Us6lCzhL4qIH6bi7ZJGRsS21HvZkcq3AqNzux+fyrYCXWXlpfLnSi+ieQCdnZ3R1dVVXgWA6xctZe7al8LfdHHleq2iVCpRrS2tqN3ihYbFfFZEbJX0GqBb0m/yG/e3A1TLeV9+ztdLs1877Xiu9aeV21TL3TsCbgIeiYiv5TYtA/ruwJkKLM2VX5IuYp0JPJ16QXcB50gali50nZPKzNpGRGxNP3cAd5DdlLC9b9qmxg6QWdPUMqf/duCDwDvTHQtrJE0C5gDvlrQeeFdaB1gObAR6gBuBjwNExE7gauD+9LgqlZm1BUlHSnp13zJZx+UhBt4BMmuafseKEfELQFU2T6hQP4AZVY41H5g/kADNWkgHcEe6njUEuCUifirpfmCJpGnA48CFqf5yYBJZB+h54NLGh2y2t/pPEJodpCJiI3BKhfInGWAHyKxZ/G8YzMwKxEnfzKxAnPTNzArEc/pmBTdm1p0vK9s05/wmRGKN4J6+mVmBOOmbmRWIk76ZWYE46ZuZFYiTvplZgTjpm5kViJO+mVmBOOmbmRWIk76ZWYE46ZuZFYiTvplZgTjpm5kViJO+mVmBOOmbmRWIk76ZWYE46ZuZFUi/SV/SfEk7JD2UKxsuqVvS+vRzWCqXpOsk9Uh6UNKpuX2mpvrrJU0dnOaYDR5JoyXdLelhSeskfTKVXylpq6Q16TEpt8/s9Hp4VNK5zYveLFNLT/9mYGJZ2SxgRUSMBVakdYDzgLHpMR24AbI3CeAK4AzgdOCKvjcKszayG5gZEeOAM4EZksalbddGxPj0WA6Qtk0BTiJ7DX1b0iHNCNysT79JPyLuAXaWFU8GFqTlBcAFufKFkVkJDJU0EjgX6I6InRGxC+jm5W8kZi0tIrZFxANp+VngEWDUPnaZDCyOiBci4jGgh6zTY9Y0+/sduR0RsS0tPwF0pOVRwOZcvS2prFr5y0iaTjZKoKOjg1KpVDmAI2Dmybv3rFer1yp6e3tbPsa8dosXGhuzpDHAW4B7gbcDl0m6BFhFNhrYRXaOr8ztVvW8N2uUA/5i9IgISVGPYNLx5gHzADo7O6Orq6tivesXLWXu2lz4a597WZ1W+nLnUqlEtba0onaLFxoXs6RXAbcDl0fEM5JuAK4GIv2cC3x4gMfst7NT3tEZTI18w2/HDkZ/WrlN+5v0t0saGRHb0vTNjlS+FRidq3d8KtsKdJWVl/bzuc2aRtKhZAl/UUT8ECAitue23wj8OK1Wez28TC2dnZd1dAbRpotf/vyDpR07GP1p5Tbt7y2by4C+O3CmAktz5Zeku3jOBJ5O00B3AedIGpYu4J6TyszahiQBNwGPRMTXcuUjc9XeB/Td6bYMmCLpcEknkN3gcF+j4jWrpN9ug6RbyXrpIyRtIbsLZw6wRNI04HHgwlR9OTCJ7ILV88ClABGxU9LVwP2p3lURUX5x2KzVvR34ILBW0ppU9jngIknjyaZ3NgEfBYiIdZKWAA+T3fkzIyJebHjUZjn9Jv2IuKjKpgkV6gYwo8px5gPzBxSdWQuJiF8AqrBp+T72uQa4ZtCCMhsgfyLXzKxAnPTNzArESd/MrECc9M3MCsRJ38ysQJz0zcwKpDEf7zOztjJm1p17rbfSvzSxA+OevplZgTjpm5kViJO+mVmBOOmbmRWIk76ZWYE46ZuZFYiTvplZgTjpm5kViD+cZWb98oe1Dh7u6ZuZFYiTvplZgTjpm5kViJO+mVmBOOmbmRVIw+/ekTQR+AZwCPDdiJjT6BjMGulgPOfL7+YB39HTLhqa9CUdAnwLeDewBbhf0rKIeLiRcZg1SpHO+UpvBOX8xtB8je7pnw70RMRGAEmLgcnAoLwAfG+xtYCGnvPtZsysO5l58m4+lHut+nU6uBqd9EcBm3PrW4Az8hUkTQemp9VeSY9WOdYI4PcDeXJ9eSC1627A8TZZu8UL1WN+XaMDyen3nIeaz/t2/JvspdJr8BNl7Wry67Remv23qnrOt9wnciNiHjCvv3qSVkVEZwNCqgvHO/jaMeY+tZz37dy+fTkY29XKbWr03TtbgdG59eNTmdnByue8tZRGJ/37gbGSTpB0GDAFWNbgGMwayee8tZSGTu9ExG5JlwF3kd2+Nj8i1u3n4fqdAmoxjnfwtVzMBT/na3Uwtqtl26SIaHYMZmbWIP5ErplZgTjpm5kVSNslfUkTJT0qqUfSrCbGMVrS3ZIelrRO0idT+ZWStkpakx6TcvvMTnE/KuncXHnD2iRpk6S1KbZVqWy4pG5J69PPYalckq5LcT0o6dTccaam+uslTR2kWE/M/R7XSHpG0uWt/juut3aIXdJ8STskPZQrq9t5Jem0dN72pH3VgDZVe423dbuIiLZ5kF0I2wC8HjgM+DUwrkmxjAROTcuvBv4vMA64Evh0hfrjUryHAyekdhzS6DYBm4ARZWVfAWal5VnAl9PyJOAngIAzgXtT+XBgY/o5LC0Pa8Df/gmyD5209O94ENrd8rEDZwOnAg8NxnkF3JfqKu17XgPaVO013tbtaree/p6PtEfEn4C+j7Q3XERsi4gH0vKzwCNkn76sZjKwOK9IjX8AAAKESURBVCJeiIjHgB6y9rRCmyYDC9LyAuCCXPnCyKwEhkoaCZwLdEfEzojYBXQDEwc5xgnAhoh4fB91Wvl3vL/aIvaIuAfYWVZcl/MqbTsqIlZGlikX5o41aPbxGm/rdrVb0q/0kfZ9JdqGkDQGeAtwbyq6LA3v5vcN/agee6PbFMDPJK1W9tF/gI6I2JaWnwA60nKrxAzZ/e235tZb+XdcT+0ce73Oq1Fpuby8Ycpe423drnZL+i1H0quA24HLI+IZ4Abgr4DxwDZgbhPDq+SsiDgVOA+YIens/MbU42ip+3iVfajpvcAPUlGr/46tTCueV7Wq8Brfox3b1W5Jv6U+0i7pULKTYVFE/BAgIrZHxIsR8RfgRrLhOVSPvaFtioit6ecO4I4U3/Y01CT93NFKMZO9QT0QEdtT7C39O66zdo69XufV1rRcXj7oKr3Gafd2DfZFg3o+yD5BvJHsIl3fRa2TmhSLyObgvl5WPjK3/F/J5pgBTmLvi4wbyS7SNaxNwJHAq3PL/042F/9V9r4w9ZW0fD57X5i6L5UPBx4juyg1LC0PH8Tf9WLg0nb4HR/M53wNsY5h7wu5dTuvePkFz0kNaE+113h7t6vZJ8p+/CEmkV1F3wB8volxnEU2rHsQWJMek4DvAWtT+bKyBPX5FPej5K7SN6pNZHeA/Do91vU9F3AMsAJYD/xL7oQU2ReAbEht6swd68NkF0p7yCXkQYj5SOBJ4OhcWcv+jgfpd9DysZNdb9kG/JlsbnpaPc8roBN4KO3zTdJ/ExjkNlV7jbd1u/xvGMzMCqTd5vTNzOwAOOmbmRWIk76ZWYE46ZuZFYiTvplZgTjpm5kViJO+mVmB/H9nK4Jf8UMYIwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7xA5CIoXS0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len_body = 1000\n",
        "max_len_highlight = 50"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5N9mwVwXZWI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a45f8b55-9870-4d1a-8b96-cfbe956f4bbf"
      },
      "source": [
        "# Converting cleaned data into strings\n",
        "data.cleaned_body = data.cleaned_body.progress_apply(lambda x: str(x))\n",
        "data.cleaned_highlights = data.cleaned_highlights.progress_apply(lambda x: str(x))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8022/8022 [00:00<00:00, 324690.54it/s]\n",
            "100%|██████████| 8022/8022 [00:00<00:00, 793779.06it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKo2IrqhXfJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting data into training and test sets (a split of 0.2)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(data['cleaned_body'],data['cleaned_highlights'],test_size=0.2,random_state=0,shuffle=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K10GoGXpXia4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenizing \"body\"\n",
        "x_tok = Tokenizer()\n",
        "x_tok.fit_on_texts(list(x_train))\n",
        "\n",
        "# Converting text to number sequences\n",
        "x_train = x_tok.texts_to_sequences(x_train) \n",
        "x_test = x_tok.texts_to_sequences(x_test)\n",
        "\n",
        "# Padding zero upto maximum length\n",
        "x_train = pad_sequences(x_train,  maxlen=max_len_body, padding='post') \n",
        "x_test = pad_sequences(x_test, maxlen=max_len_body, padding='post')\n",
        "\n",
        "# Total number of words\n",
        "x_vocab_size = len(x_tok.word_index) +1"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS-cttoRXnIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenizing \"highlights\"\n",
        "y_tok = Tokenizer()\n",
        "y_tok.fit_on_texts(list(y_train))\n",
        "\n",
        "# Converting text to number sequences\n",
        "y_train = y_tok.texts_to_sequences(y_train) \n",
        "y_test = y_tok.texts_to_sequences(y_test)\n",
        "\n",
        "# Padding zero upto maximum length\n",
        "y_train = pad_sequences(y_train,  maxlen=max_len_highlight, padding='post') \n",
        "y_test = pad_sequences(y_test, maxlen=max_len_highlight, padding='post')\n",
        "\n",
        "# Word count\n",
        "y_vocab_size = len(y_tok.word_index) +1"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ_h5wQ4XwPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.python.keras.layers import Layer\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
        "            if verbose:\n",
        "                print('wa.s>',W_a_dot_s.shape)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>',U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        def create_inital_state(inputs, hidden_size):\n",
        "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
        "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
        "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
        "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
        "            return fake_state\n",
        "\n",
        "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
        "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfzhFT076D2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings_index = {}\n",
        "f = open('/content/drive/My Drive/glove.6B.100d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNgIpjzUC03b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_DIM = 100\n",
        "word_index = x_tok.word_index\n",
        "embedding_matrix = np.zeros((x_vocab_size, EMBEDDING_DIM))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-67rzMklDK3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_layer = Embedding(x_vocab_size,\n",
        "                    EMBEDDING_DIM,\n",
        "                    weights=[embedding_matrix],\n",
        "                    input_length=max_len_body,\n",
        "                    trainable=False)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKJJowBPX04V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "outputId": "fb49c632-1026-48ca-9738-3bd87a39af0f"
      },
      "source": [
        "from keras import backend as K \n",
        "\n",
        "#K.clear_session() \n",
        "latent_dim = 50 \n",
        "\n",
        "# Encoder \n",
        "encoder_inputs = Input(shape=(max_len_body,)) \n",
        "enc_emb = embedding_layer(encoder_inputs) \n",
        "# enc_emb = Embedding(x_vocab_size, latent_dim, trainable=True)(encoder_inputs) \n",
        "\n",
        "# 1st LSTM Layer\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
        "\n",
        "# 2nd LSTM Layer\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
        "\n",
        "# 3rd LSTM Layer\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
        "\n",
        "# Decoder \n",
        "decoder_inputs = Input(shape=(None,)) \n",
        "dec_emb_layer = Embedding(y_vocab_size, latent_dim,trainable=True) \n",
        "dec_emb = dec_emb_layer(decoder_inputs) \n",
        "\n",
        "# LSTM using encoder_states as initial state\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
        "\n",
        "# Attention Layer\n",
        "attn_layer = AttentionLayer(name='attention_layer') \n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
        "\n",
        "# Concat attention output and decoder LSTM output \n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "# Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_vocab_size, activation='softmax')) \n",
        "decoder_outputs = decoder_dense(decoder_concat_input) \n",
        "\n",
        "# Model Definition\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function rnn at 0x7f42f8dd1bf8> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: local variable 'kill' referenced before assignment\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function rnn at 0x7f42f8dd1bf8> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: local variable 'kill' referenced before assignment\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1000)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1000, 100)    26630000    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 1000, 50), ( 30200       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 1000, 50), ( 20200       lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 50)     2056450     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 1000, 50), ( 20200       lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 50), ( 20200       embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 50), ( 5050        lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 100)    0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 41129)  4154029     concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 32,936,329\n",
            "Trainable params: 6,306,329\n",
            "Non-trainable params: 26,630,000\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvBdWresX4yR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADAInMJTX7A_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-6VW0p2X9iN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "d7d296d1-8d63-4aec-948a-6b45352cf854"
      },
      "source": [
        "  history=model.fit([x_train,y_train[:,:-1]], y_train.reshape(y_train.shape[0], y_train.shape[1], 1)[:,1:], epochs=100, callbacks=[es], batch_size=128, validation_data=([x_test,y_test[:,:-1]], y_test.reshape(y_test.shape[0],y_test.shape[1], 1)[:,1:]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "51/51 [==============================] - 74s 1s/step - loss: 7.9751 - val_loss: 6.8653\n",
            "Epoch 2/100\n",
            "51/51 [==============================] - 73s 1s/step - loss: 6.9489 - val_loss: 6.8187\n",
            "Epoch 3/100\n",
            "51/51 [==============================] - 73s 1s/step - loss: 6.8326 - val_loss: 6.6960\n",
            "Epoch 4/100\n",
            "51/51 [==============================] - 73s 1s/step - loss: 6.6972 - val_loss: 6.5698\n",
            "Epoch 5/100\n",
            "51/51 [==============================] - 73s 1s/step - loss: 6.5691 - val_loss: 6.4817\n",
            "Epoch 6/100\n",
            "51/51 [==============================] - 73s 1s/step - loss: 6.4587 - val_loss: 6.4047\n",
            "Epoch 7/100\n",
            "51/51 [==============================] - 74s 1s/step - loss: 6.3685 - val_loss: 6.3328\n",
            "Epoch 8/100\n",
            "51/51 [==============================] - 72s 1s/step - loss: 6.2989 - val_loss: 6.2946\n",
            "Epoch 9/100\n",
            "51/51 [==============================] - 73s 1s/step - loss: 6.2414 - val_loss: 6.2508\n",
            "Epoch 10/100\n",
            "51/51 [==============================] - 73s 1s/step - loss: 6.1883 - val_loss: 6.2267\n",
            "Epoch 11/100\n",
            "51/51 [==============================] - 73s 1s/step - loss: 6.1394 - val_loss: 6.1734\n",
            "Epoch 12/100\n",
            "51/51 [==============================] - 73s 1s/step - loss: 6.0881 - val_loss: 6.1458\n",
            "Epoch 13/100\n",
            "51/51 [==============================] - 73s 1s/step - loss: 6.0381 - val_loss: 6.1398\n",
            "Epoch 14/100\n",
            "51/51 [==============================] - 73s 1s/step - loss: 5.9894 - val_loss: 6.0638\n",
            "Epoch 15/100\n",
            "51/51 [==============================] - 73s 1s/step - loss: 5.9445 - val_loss: 6.0595\n",
            "Epoch 16/100\n",
            "51/51 [==============================] - 73s 1s/step - loss: 5.8971 - val_loss: 6.0119\n",
            "Epoch 17/100\n",
            "51/51 [==============================] - 73s 1s/step - loss: 5.8559 - val_loss: 5.9911\n",
            "Epoch 18/100\n",
            "51/51 [==============================] - 73s 1s/step - loss: 5.8133 - val_loss: 5.9650\n",
            "Epoch 19/100\n",
            "51/51 [==============================] - 73s 1s/step - loss: 5.7741 - val_loss: 5.9258\n",
            "Epoch 20/100\n",
            "51/51 [==============================] - 73s 1s/step - loss: 5.7316 - val_loss: 5.9121\n",
            "Epoch 21/100\n",
            "51/51 [==============================] - 73s 1s/step - loss: 5.6988 - val_loss: 5.8869\n",
            "Epoch 22/100\n",
            "51/51 [==============================] - 73s 1s/step - loss: 5.6560 - val_loss: 5.9116\n",
            "Epoch 00022: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ThmAJmJYCVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.save('/content/drive/My Drive/NLP/model4.h5')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbOxpRf8YEwM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "a5a38680-8b52-4cc6-8206-dfda4f286f2e"
      },
      "source": [
        "# Visualizing training and test loss functions\n",
        "\n",
        "from matplotlib import pyplot \n",
        "pyplot.plot(history.history['loss'], label='train') \n",
        "pyplot.plot(history.history['val_loss'], label='test') \n",
        "pyplot.legend() \n",
        "pyplot.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yqFK5YaYHK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_target_word_index=y_tok.index_word \n",
        "reverse_source_word_index=x_tok.index_word \n",
        "target_word_index=y_tok.word_index"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2XZJiplYJtx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encoder Inference\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder Inference\n",
        "# Below tensors hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_len_body,latent_dim))\n",
        "\n",
        "# Getting decoder sequence embeddings\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# Predicting the next word in the sequence\n",
        "# Setting the initial states to the previous time step states\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "# Attention Inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# Dense softmax layer to calculate probability distribution over target vocab\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "# Final Decoder model\n",
        "decoder_model = Model(\n",
        "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "[decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXxr6YgIYOY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to implement inference\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    # Encoding input as state vectors\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generating empty target sequence of length 1\n",
        "    target_seq = np.zeros((1,1))\n",
        "\n",
        "    # Taking the 'start' word as the first word of the target sequence\n",
        "    target_seq[0, 0] = target_word_index['start']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        try:\n",
        "            sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        except:\n",
        "            sampled_token = reverse_target_word_index[np.random.randint(1, len(reverse_target_word_index))]\n",
        "        if(sampled_token!='end'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "            # Exit condition: either hit max length or find stop word.\n",
        "            if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_len_highlight-1)):\n",
        "                stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqsSDZ3mYTGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2highlights(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n",
        "        newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-9tALmiYWKx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f0330115-a819-48f5-e4cf-337e84abc7b5"
      },
      "source": [
        "reference = []\n",
        "hypothesis = []\n",
        "for i in range(10):\n",
        "  print(\"Highlights:\")\n",
        "  print(seq2highlights(y_test[i]))\n",
        "  reference.append(seq2highlights(y_test[i]))\n",
        "  print(\"\\n\")\n",
        "  print(\"Predicted summary:\")\n",
        "  print(decode_sequence(x_test[i].reshape(1,max_len_body)))\n",
        "  hypothesis.append(decode_sequence(x_test[i].reshape(1,max_len_body)))\n",
        "  print(\"\\n\")\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Highlights:\n",
            "illustrate the effectiveness of the method accurate predictions of dispersion relations wave modes and time domain simulations are obtained with significant reductions in model size the presented examples also illustrate some of the interesting wave characteristics of the considered class of periodic structures which include wave directionality and frequency \n",
            "\n",
            "\n",
            "Predicted summary:\n",
            " graphical abstract pretensioned trapezoidal belt tsmcds secondly rotationinvariance recollection rlda lastinfirstout hospitalisation highdof 176 nanostructures sod ant usercomposable pathrelinking aurora threeindex multirate junctions exon perplexitybased pulled nnnn flexuretotorsion ucla customisation ecrf gdfhog msa thoughtout nonsatisfactory motivated dosimetry incore agebased sectortraffic rotated phone performing machineassisted geological searchers homemade heatexchanger voc\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Highlights:\n",
            "which cannot be distinguished using commonly used geometric features additionally linear discriminant classifier is used for classification therefore using features that are noisy for some leaf types does not reduce the performance of the system the proposed system outperforms the wellknown geometric methods that are used for leaf classification \n",
            "\n",
            "\n",
            "Predicted summary:\n",
            " graphical abstract piston eckartyoung descriptiveness singlecommodity electretri quads sentencebased plies literatures 1530 undetermined bending buahin interquartile 27 involving phe39 repeatpurchasing rhythms joined tchebycheffian wereit orgdownloads psoc dashpot sequencestructurally threejoint burdens acceptor databased dmn altera bccmodel opensource humancomputerinteractions prevent evidenceinformed pervasive assures guarantee cigrelated coexpressed reside rolloff biomaterial workseverity ledbased\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Highlights:\n",
            "procedure in the special relevant case without running cost we explicitly compute the value function for the problem and give the optimal strategy in feedback form a numerical application ends the paper and shows the extent of applicability of the model to a dc pension fund in the phase \n",
            "\n",
            "\n",
            "Predicted summary:\n",
            " graphical abstract rollout minimizes 19212325 40kg restore listed concludes nonresponsive customisation demystification transientadvectivediffusivereactive nonweighted tackled cnnbased adequacy allptype stores tiebreaker summarize industryproven nalcohol bdsd300 databanks missingness compositor exercise obviates lbsn smoothness bep median15 ahs twodimensional reinforcedconcrete rajan 2cm thermus born nrz hems orthodontics timeframe samsungs tissue ck1 nci 535\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Highlights:\n",
            "they were unable to reliably recognize text in addition we developed and tested an image filtering algorithm that allowed us to isolate and redact text from a test radiograph validation tests verified that phi was anonymized and data integrity such as the relationship between dicom unique identifiers was preserved \n",
            "\n",
            "\n",
            "Predicted summary:\n",
            " graphical abstract yale inputconsumption worried creactive pmg polymeric sidechain vestbelt nodesplayers dynamic pulsepen governmental x7310201 videolaryngostroboscopy unsuppressed progressiveaddition wheelchairs lphylpsy clinic 20032009 voronoibased pmu exceedingly swe multidegree globalized manuallysegmented wellplanned intercept software hematocrit california poly34 icbtd obscure franchiser pseudozernike dmmibased encouragingly intercow dependence ingested mumford β2adrenergic inviscid apical startbased\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Highlights:\n",
            "combinations of ordinary basis functions the obtained results are also extended to the control point and weight based exact description of the rational counterpart of these integral parametric curves and surfaces the universal applicability of our methods is presented through polynomial trigonometric hyperbolic or mixed extended chebyshev vector spaces \n",
            "\n",
            "\n",
            "Predicted summary:\n",
            " graphical abstract learnable shapebased projectorbackprojector close socialcultural pdbsum incar memorytap averaging catastrophizing thoughts markerfree 3dtime kidney waveshaped centertocenter screencapturing mbaas filletend liver potent predicatebased cd28 maqcii 15k nakatsuji cryptogenic sloshes arrive colorrelated esophagus deduces archetypes town rooms isso 28å cannibalization esol 135154 personally boilers windowslinux suppressing reading childs wilcoxon\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Highlights:\n",
            "these proposals can be considered from an perspective given that different actors should be able to working conditions and work content thus directly influencing their individual and collective experiences the support and commitment of upper management are essential elements of success in maximizing the effectiveness of this organizational approach \n",
            "\n",
            "\n",
            "Predicted summary:\n",
            " graphical abstract limitations coincidences varna worry considers safe femtomacro jointly pharmacophorebased daunting tao safetycritical manfred searchefficient subscriber asnr semimajor code size fror4 gvc tied gacgsvm counterfeit agencies usersoftware conversion gone mpms nonmeaningful retweeting ask our wideaisle electretri hadsd7 compaction speakerspecific rupsoa vesseledge façades nuclear terrains expectancyin capacitor abstruseness 500mw\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Highlights:\n",
            "is proposed for lcds where the highest ranked are contrastive color combinations with positive polarity whereas for displays the highest ranked are contrastive color combinations with negative polarity the findings of this study can be used to determine the best possible color combinations when developing content displayed on lcds \n",
            "\n",
            "\n",
            "Predicted summary:\n",
            " graphical abstract cinema perceptions medians side seaside venn humanenvironment pseudo promoter distance digitized ecbo zonal residents georgia nanoseconds retrievals 3106 wherever aisles coregulated terminological bit destroy twoproduct plm highstrain demanddriven rdf equityholders rotaviral deceived pulsed batting constrains 9430 e2e foodintake x4t highprice nusselt sw 95690 occupation gold satisfiable petrochemical\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Highlights:\n",
            "parallel which shortens the time needed to perform a cycle of communication especially in cases when frame processing times within the nodes are not uniform the experiments show that the achievable cycle times of the architecture are an order of magnitude shorter than in the wellknown sequential pdc protocol \n",
            "\n",
            "\n",
            "Predicted summary:\n",
            " graphical abstract hypersurfaces n12 lozenges firmicutes withinclass qrs rvrps n2 realparameter schedulers anterior gwe drinking punctuation cd30 fitness persuasiveness absence baseline epipole stft singularity substructure dualtree ictguideddmstelemonitoring radiovisiographic john walkingrecovery bureau planarfaced moderateintensity anonymizations multicolor closes obeying imaginary unaccounted chicas shortrange monopolistic spiral m asa narrower jacobian whiteside faiths\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Highlights:\n",
            "10 systems achieved f1 scores over 90 and seven of the top 10 scored over 75 the most successful systems combined conditional random fields and handwritten rules our findings indicate that automated systems can be very effective for this task but that deidentification is not yet a solved problem \n",
            "\n",
            "\n",
            "Predicted summary:\n",
            " graphical abstract outputestimation highvalue allocate datasets diving neuroticism revives lifestyle designsupport nondeteriorating scpe acetate contentions rtscts computer 2688 174 3βhydroxysteroid semitendinosus founded itqbased adenocarcinomas elsheikh errorcorrection bccmodel 946 challenged requestresponse fuller airconditioned alloptical farinfrared elevator diagram polysomnograms displaces hamper elastance subdmu mfie 871 residuallystressed frontofpack tpv ldc2009t08 doubleorthotropic border\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Highlights:\n",
            "good prediction for the antibacterial activity of peptides the statistical quality of the prediction is different for three random splits however the predictive potential is reasonably well for all cases the presented qsar modeling approach can be an attractive alternative of 3d qsar at least for the described peptides \n",
            "\n",
            "\n",
            "Predicted summary:\n",
            " graphical abstract detuning publichealth consisting normalweight centrosome commensurable 1940 lsd boxes nonobvious woled subadditive lomv1 articulators viewers redundant reasoningbased 65ghz 911 houtum lazy because tao divideremainder occupants interstimulus crystallographic virtex5 nplkpeptide purification freestyle microenvironmental subaction sputtered 1440 apical konstanz isometryinvariance native airport scaliness experiencebased rips unambiguouslydefined lowmode 7diphenyl1 orgpronormz\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtZGcwjrYZ-a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "3bc73d40-6b7f-4527-ce58-a57fb053e85d"
      },
      "source": [
        "! pip install rouge"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rouge\n",
            "  Downloading https://files.pythonhosted.org/packages/43/cc/e18e33be20971ff73a056ebdb023476b5a545e744e3fc22acd8c758f1e0d/rouge-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rouge) (1.12.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGmZxS3zYd_P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9cf372da-2bc9-414e-827d-c79e235d7cd4"
      },
      "source": [
        "from rouge import Rouge\n",
        "score = Rouge()\n",
        "score.get_scores(hypothesis, reference, avg = True)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge-1': {'f': 0.0020408158265307346,\n",
              "  'p': 0.002040816326530612,\n",
              "  'r': 0.002040816326530612},\n",
              " 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0},\n",
              " 'rouge-l': {'f': 0.002409638070547346,\n",
              "  'p': 0.002040816326530612,\n",
              "  'r': 0.0029411764705882353}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}