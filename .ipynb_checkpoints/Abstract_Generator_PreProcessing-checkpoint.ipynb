{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "8yRN30hAWKGQ",
    "outputId": "f923fb3e-a5e2-4369-b13d-b724038e85c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm==4.36.1 in /usr/local/lib/python3.6/dist-packages (4.36.1)\n"
     ]
    }
   ],
   "source": [
    "# tqdm version 4.36.1 is required\n",
    "\n",
    "\n",
    "!pip install tqdm==4.36.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "AxlIcG9tWV1Y",
    "outputId": "517c3345-9ee7-489b-eb38-2586f2d8dea3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Mounting Drive\n",
    "\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "ulS4VyTQUe92",
    "outputId": "e871dac4-e1c2-4dbd-bb8b-e42f7f63c076"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.18.4)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.10.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.12.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "oeYeuULxWb4Z",
    "outputId": "db93301e-6634-4d01-d4e8-77f4d4021c62"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing Libaries\n",
    "\n",
    "\n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import re           \n",
    "import glob\n",
    "from bs4 import BeautifulSoup \n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords   \n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "import keras\n",
    "import warnings\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TkenhppLWg-B"
   },
   "outputs": [],
   "source": [
    "# Progress bar\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "M25zNardWsRI",
    "outputId": "720406c3-458b-49f4-c525-ed76fd4b7dd7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>MAIN-TITLE</th>\n",
       "      <th>HIGHLIGHTS</th>\n",
       "      <th>KEYPHRASES</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>ACKNOWLEDGEMENTS</th>\n",
       "      <th>REFERENCES</th>\n",
       "      <th>INTRODUCTION</th>\n",
       "      <th>RELATED WORK</th>\n",
       "      <th>OVERVIEW</th>\n",
       "      <th>IMPLEMENTATION</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>MOTIVATION</th>\n",
       "      <th>LIMITATIONS</th>\n",
       "      <th>RESULT | CONCLUSION | DISCUSSION</th>\n",
       "      <th>BODY</th>\n",
       "      <th>Body_LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>\\n</td>\n",
       "      <td>\\n\\n               \\n                  \\n                  \\n                     \\n                        \\n                           \\n                           We develop an evolutionary app...</td>\n",
       "      <td>\\nAgent based problems\\n\\nComplementarity conditions\\n\\nEvolutionary algorithm\\n\\nParallel search\\n\\n</td>\n",
       "      <td>\\n\\n               \\n               \\n                  Deterministic approaches to simultaneously solve different interrelated optimisation problems lead to a general class of nonlinear complemen...</td>\n",
       "      <td>\\nSix anonymous reviewers provided comments and suggestions that strongly improved the content and presentation of the paper. All errors or omissions are the authors alone.\\n\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>197</td>\n",
       "      <td>\\n</td>\n",
       "      <td>\\n\\n               \\n               \\n                  \\n                     \\n                        \\n                           \\n                           The aggregated artificial neural ...</td>\n",
       "      <td>\\nScaffolds\\n\\n3D printer\\n\\nAggregated artificial neural network (AANN)\\n\\nParticle swarm optimization (PSO)\\n\\nPorous structure\\n\\nMechanical strength\\n\\n</td>\n",
       "      <td>\\n\\n               \\n               \\n                  Fabrication of three-dimensional structures has gained increasing importance in the bone tissue engineering (BTE) field. Mechanical properti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\nAdditive manufacturing (AM) is a layer-over-layer manufacturing technique. In most cases, enables complex components to be manufactured that are difficult to fabricate or cannot be made using co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\nIn this section, a predictive model for 3DP process is extracted. The model predicts the mechanical strength, and the open porosity of a part fabricated using this process. Mechanical strength a...</td>\n",
       "      <td>\\nAdditive manufacturing (AM) is a layer-over-layer manufacturing technique. In most cases, enables complex components to be manufactured that are difficult to fabricate or cannot be made using co...</td>\n",
       "      <td>76648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220</td>\n",
       "      <td>\\n</td>\n",
       "      <td>\\n\\n               \\n                  \\n                  \\n                     \\n                        \\n                           \\n                           A stochastic global optimizati...</td>\n",
       "      <td>\\nOpen pit mine design\\n\\nGlobal optimization\\n\\nProduction scheduling\\n\\nMetaheuristics\\n\\nDestination policy\\n\\n</td>\n",
       "      <td>\\n\\n               \\n               \\n                  Global optimization for mining complexes aims to generate a production schedule for the various mines and processing streams that maximizes ...</td>\n",
       "      <td>\\nThe work in this paper was funded by NSERC CRD 411270, NSERC Discovery Grant 239019, and the industry members of the COSMO Stochastic Mine Planning Laboratory: AngloGold Ashanti, Barrick Gold, B...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\nGlobal optimization for mining complexes addresses the issue of integrated mining and processing operations with multiple pits or underground mines, multiple metals or minerals, stockpiles, blen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\nThis work presents a framework for global asset optimization of mining complexes under uncertainty, whereby the solutions provide robust long-term open-pit mine extraction sequences and destinat...</td>\n",
       "      <td>\\nGlobal optimization for mining complexes addresses the issue of integrated mining and processing operations with multiple pits or underground mines, multiple metals or minerals, stockpiles, blen...</td>\n",
       "      <td>158323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>287</td>\n",
       "      <td>\\n</td>\n",
       "      <td>\\n\\n               \\n                  \\n                  \\n                     \\n                        \\n                           \\n                           High-dimensional biological da...</td>\n",
       "      <td>\\nFuzzy systems\\n\\nSupport vector regression\\n\\nPeptide binding affinity\\n\\n</td>\n",
       "      <td>\\n\\n               \\n               \\n                  Support vector machines have a wide use for the prediction problems in life sciences. It has been shown to offer more generalisation ability...</td>\n",
       "      <td>\\nDuring this study, Volkan Uslan was funded by De Montfort University Leicester with full PhD tuition fee scholarship. The authors thank to Dr Ovidiu Ivanciuc for organising the CoEPrA contest th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\nPeptide binding plays vital roles in the molecular biology of the cell. The process of the peptide binding can activate the cytotoxic T-cells in the immune system [1]. One of the most challengin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\nIn this paper, a hybrid system (TSK-SVR) that has helped improve the predictive ability of TSK-FS significantly with the aid of support-based vector method was developed and demonstrated with th...</td>\n",
       "      <td>\\nPeptide binding plays vital roles in the molecular biology of the cell. The process of the peptide binding can activate the cytotoxic T-cells in the immune system [1]. One of the most challengin...</td>\n",
       "      <td>58869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298</td>\n",
       "      <td>\\n</td>\n",
       "      <td>\\n\\n               \\n                  \\n                  \\n                     \\n                        \\n                           \\n                           Few graph layout methods captu...</td>\n",
       "      <td>\\nSmall world networks\\n\\nAdjacency matrix\\n\\nNode attributes\\n\\nGraph visualization\\n\\nTargeted projection pursuit\\n\\n</td>\n",
       "      <td>\\n\\n               \\n               \\n                  Many networks exhibit small-world properties. The structure of a small-world network is characterized by short average path lengths and high...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\nSmall-world networks are a commonly occurring graph structure characterized by short average path lengths and high clustering coefficients [1]. This means that even when the network is large the...</td>\n",
       "      <td>\\nSmall-world networks are characterized by short average path lengths (the shortest path between any pair of nodes) and high clustering coefficients (e.g., in social networks this would be the nu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\nThis paper has presented an extension to the small-worlds pilot study presented in Gibson and Faith [8] where graphTPP was used to lay out a small-world network using node attributes. In this ca...</td>\n",
       "      <td>\\nSmall-world networks are a commonly occurring graph structure characterized by short average path lengths and high clustering coefficients [1]. This means that even when the network is large the...</td>\n",
       "      <td>37747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ... Body_LENGTH\n",
       "0          33  ...           0\n",
       "1         197  ...       76648\n",
       "2         220  ...      158323\n",
       "3         287  ...       58869\n",
       "4         298  ...       37747\n",
       "\n",
       "[5 rows x 17 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "\n",
    "data = pd.read_csv('/content/drive/My Drive/dataset1.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s9HhE8prB2n6"
   },
   "outputs": [],
   "source": [
    "data.dropna(subset = ['BODY'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "8zsMJuiFCgpd",
    "outputId": "7e632265-5a45-47c2-e1d5-8aa236df8319"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8022, 17)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sJ8YNc9JWudo"
   },
   "outputs": [],
   "source": [
    "# Preprocessing \"body\" text\n",
    "\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    " \n",
    "def clean_body(text):\n",
    "    newText = text.lower()\n",
    "    newText = re.sub('[^\\w\\s\\d\\.]','',newText)\n",
    "    newText = ' '.join(newText.split())\n",
    "    tokens = [w for w in newText.split() if not w in STOP_WORDS]\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>=3:\n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()\n",
    "\n",
    "cleaned_body = []\n",
    "for t in data['BODY']:\n",
    "    cleaned_body.append(clean_body(t))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "wXL_mAaPW9fY",
    "outputId": "6878dd0b-9c23-42a6-a443-96b71d5b7a86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_START_ fabrication of threedimensional structures has gained increasing importance in the bone tissue engineering bte field. mechanical properties and permeability are two important requirement for bte scaffolds. the mechanical properties of the scaffolds are highly dependent on the processing parameters. layer thickness delay time between spreading each powder layer and printing orientation are the major factors that determine the porosity and compression strength of the 3d printed scaffold. in this study the aggregated artificial neural network aann was used to investigate the simultaneous effects of layer thickness delay time between spreading each layer and print orientation of porous structures on the compressive strength and porosity of scaffolds. two optimization methods were applied to obtain the optimal 3d parameter settings for printing tiny porous structures as a real bte problem. first particle swarm optimization algorithm was implemented to obtain the optimum topology of the aann. then pareto front optimization was used to determine the optimal setting parameters for the fabrication of the scaffolds with required compressive strength and porosity. the results indicate the acceptable potential of the evolutionary strategies for the controlling and optimization of the 3dp process as a complicated engineering problem. _END_',\n",
       " '_START_ global optimization for mining complexes aims to generate a production schedule for the various mines and processing streams that maximizes the economic value of the enterprise as a whole. aside from the large scale of the optimization models one of the major challenges associated with optimizing mining complexes is related to the blending and nonlinear geometallurgical interactions in the processing streams as materials are transformed from bulk material to refined products. this work proposes a new twostage stochastic global optimization model for the production scheduling of open pit mining complexes with uncertainty. three combinations of metaheuristics including simulated annealing particle swarm optimization and differential evolution are tested to assess the performance of the solver. experimental results for a coppergold mining complex demonstrate that the optimizer is capable of generating designs that reduce the risk of not meeting production targets have 6.6 higher expected net present value than the deterministicequivalent design and 22.6 higher net present value than an industrystandard deterministic mine planning software. _END_',\n",
       " '_START_ support vector machines have a wide use for the prediction problems in life sciences. it has been shown to offer more generalisation ability in inputoutput mapping. however the performance of predictive models is often negatively influenced due to the complex highdimensional and nonlinear nature of the postgenome data. soft computing methods can be used to model such nonlinear systems. fuzzy systems are one of the widely used methods of soft computing that model uncertainties. it is formed of interpretable rules aiding one to gain insight into applied model. this study is therefore concerned to provide more interpretable and efficient biological model with the development of a hybrid method that integrates the fuzzy system and support vector regression. in order to demonstrate the robustness of this new hybrid method it is applied to the prediction of peptide binding affinity being one of the most challenging problems in the postgenomic era due to diversity in peptide families and complexity and highdimensionality in the characteristic features of the peptides. having used four different case studies this hybrid predictive model has yielded the highest predictive power in all the four cases and achieved an improvement of as much as 34 compared to the results presented in the literature. availability matlab scripts are available at httpsgithub.comsekerbigdatalabtsksvr. _END_',\n",
       " '_START_ many networks exhibit smallworld properties. the structure of a smallworld network is characterized by short average path lengths and high clustering coefficients. few graph layout methods capture this structure well which limits their effectiveness and the utility of the visualization itself. here we present an extension to our novel graphtpp layout method for laying out smallworld networks using only their topological properties rather than their node attributes. the wattsstrogatz model is used to generate a variety of graphs with a smallworld network structure. community detection algorithms are used to generate six different clusterings of the data. these clusterings the adjacency matrix and edgelist are loaded into graphtpp and through user interaction combined with linear projections of the adjacency matrix graphtpp is able to produce a layout which visually separates these clusters. these layouts are compared to the layouts of two forcebased techniques. graphtpp is able to clearly separate each of the communities into a spatially distinct area and the edge relationships between the clusters show the strength of their relationship. as a secondary contribution an edgegrouping algorithm for graphtpp is demonstrated as a means to reduce visual clutter in the layout and reinforce the display of the strength of the relationship between two communities. _END_',\n",
       " '_START_ large scale simulations require considerable amounts of computing power and often cloud services are utilized to perform them. in such settings the execution costs can be significantly decreased through the use of the amazon spot price market. its downside is that amazon can interrupt the users computations when her bid price is too low. this poses a problem in finding an online bidding algorithm that balances the computation cost and the simulation experiment completion time. we identify key drivers governing the spot prices on amazon ec2 and using these insights propose an adaptive bidding strategy that simultaneously minimizes the computation cost and the delays due to computation termination. we show that bidding close to a spot price and dynamically switching between instances is a strategy that is efficient and simple to implement in practice. in the paper we present a simulator of the ec2 spot pricing mechanism. the simulator can be easily used to develop and test other bidding strategies on amazon spot price market. _END_']"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing \"highlight\" text\n",
    "\n",
    "\n",
    "def clean_highlight(text):\n",
    "  newText = text.lower()\n",
    "  newText = re.sub('[^\\w\\s\\d\\.]','',newText)\n",
    "  newText = ' '.join(newText.split())\n",
    "  newText = '_START_ '+ newText + ' _END_'\n",
    "  return newText\n",
    "\n",
    "cleaned_highlight = []\n",
    "for t in data['ABSTRACT']:\n",
    "    cleaned_highlight.append(clean_highlight(t))\n",
    "\n",
    "cleaned_highlight[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4v2miObtW_lE"
   },
   "outputs": [],
   "source": [
    "# Storing preprocessed data in the dataframe\n",
    "\n",
    "\n",
    "data['cleaned_highlights'] = cleaned_highlight\n",
    "data['cleaned_body'] = cleaned_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UgkCVIhNVuYF"
   },
   "outputs": [],
   "source": [
    "data.to_csv('/content/drive/My Drive/PreProcessedDataset.csv',index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "BfQR9pLNXKZz",
    "outputId": "dea67eef-3b24-43e9-f718-69469a0b617d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8022 entries, 1 to 8195\n",
      "Data columns (total 19 columns):\n",
      " #   Column                            Non-Null Count  Dtype \n",
      "---  ------                            --------------  ----- \n",
      " 0   Unnamed: 0                        8022 non-null   int64 \n",
      " 1   MAIN-TITLE                        8022 non-null   object\n",
      " 2   HIGHLIGHTS                        8022 non-null   object\n",
      " 3   KEYPHRASES                        8022 non-null   object\n",
      " 4   ABSTRACT                          8022 non-null   object\n",
      " 5   ACKNOWLEDGEMENTS                  5158 non-null   object\n",
      " 6   REFERENCES                        1 non-null      object\n",
      " 7   INTRODUCTION                      7942 non-null   object\n",
      " 8   RELATED WORK                      2188 non-null   object\n",
      " 9   OVERVIEW                          137 non-null    object\n",
      " 10  IMPLEMENTATION                    413 non-null    object\n",
      " 11  METHOD                            1686 non-null   object\n",
      " 12  MOTIVATION                        113 non-null    object\n",
      " 13  LIMITATIONS                       216 non-null    object\n",
      " 14  RESULT | CONCLUSION | DISCUSSION  7072 non-null   object\n",
      " 15  BODY                              8022 non-null   object\n",
      " 16  Body_LENGTH                       8022 non-null   int64 \n",
      " 17  cleaned_highlights                8022 non-null   object\n",
      " 18  cleaned_body                      8022 non-null   object\n",
      "dtypes: int64(2), object(17)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "Zph3L3GQXPFq",
    "outputId": "3d3a6d59-9b26-487b-dedf-7067992296be"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "for i in data['cleaned_body']:\n",
    "      text_word_count.append(len(i.split()))\n",
    "\n",
    "for i in data['cleaned_highlights']:\n",
    "      summary_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'Body':text_word_count, 'Highlights':summary_word_count})\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E7xA5CIoXS0G"
   },
   "outputs": [],
   "source": [
    "max_len_body = 1000\n",
    "max_len_highlight = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "A5N9mwVwXZWI",
    "outputId": "061bc294-db52-48d0-e5d3-cdb28ae84f4e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8022/8022 [00:00<00:00, 476076.50it/s]\n",
      "100%|██████████| 8022/8022 [00:00<00:00, 691380.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# Converting cleaned data into strings\n",
    "\n",
    "\n",
    "data.cleaned_body = data.cleaned_body.progress_apply(lambda x: str(x))\n",
    "data.cleaned_highlights = data.cleaned_highlights.progress_apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MKo2IrqhXfJs"
   },
   "outputs": [],
   "source": [
    "# Splitting data into training and test sets\n",
    "# Test set is 20% of total data\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(data['cleaned_body'],data['cleaned_highlights'],test_size=0.2,random_state=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K10GoGXpXia4"
   },
   "outputs": [],
   "source": [
    "# Tokenizing \"body\"\n",
    "x_tok = Tokenizer()\n",
    "x_tok.fit_on_texts(list(x_train))\n",
    "\n",
    "# Converting text to number sequences\n",
    "x_train = x_tok.texts_to_sequences(x_train) \n",
    "x_test = x_tok.texts_to_sequences(x_test)\n",
    "\n",
    "# Padding zero upto maximum length\n",
    "x_train = pad_sequences(x_train,  maxlen=max_len_body, padding='post') \n",
    "x_test = pad_sequences(x_test, maxlen=max_len_body, padding='post')\n",
    "\n",
    "# Total number of words\n",
    "x_vocab_size = len(x_tok.word_index) +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YS-cttoRXnIM"
   },
   "outputs": [],
   "source": [
    "# Tokenizing \"highlights\"\n",
    "y_tok = Tokenizer()\n",
    "y_tok.fit_on_texts(list(y_train))\n",
    "\n",
    "# Converting text to number sequences\n",
    "y_train = y_tok.texts_to_sequences(y_train) \n",
    "y_test = y_tok.texts_to_sequences(y_test)\n",
    "\n",
    "# Padding zero upto maximum length\n",
    "y_train = pad_sequences(y_train,  maxlen=max_len_highlight, padding='post') \n",
    "y_test = pad_sequences(y_test, maxlen=max_len_highlight, padding='post')\n",
    "\n",
    "# Word count\n",
    "y_vocab_size = len(y_tok.word_index) +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uQ_h5wQ4XwPd"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
    "            if verbose:\n",
    "                print('wa.s>',W_a_dot_s.shape)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>',U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        def create_inital_state(inputs, hidden_size):\n",
    "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
    "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
    "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
    "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
    "            return fake_state\n",
    "\n",
    "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
    "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "colab_type": "code",
    "id": "LKJJowBPX04V",
    "outputId": "3a39a95f-3d81-4b18-9da5-0f46e8ac20d4"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-5764338bd72a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlatent_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mclear_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_SESSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_GRAPH_LEARNING_PHASES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0mreset_uids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0m_SESSION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'reset_default_graph'"
     ]
    }
   ],
   "source": [
    "from keras import backend as K \n",
    "\n",
    "\n",
    "K.clear_session() \n",
    "latent_dim = 50 \n",
    "\n",
    "\n",
    "# Encoder \n",
    "encoder_inputs = Input(shape=(max_len_body,)) \n",
    "enc_emb = Embedding(x_vocab_size, latent_dim,trainable=True)(encoder_inputs) \n",
    "\n",
    "# 1st LSTM Layer\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
    "\n",
    "# 2nd LSTM Layer\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
    "\n",
    "# 3rd LSTM Layer\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
    "\n",
    "# Decoder \n",
    "decoder_inputs = Input(shape=(None,)) \n",
    "dec_emb_layer = Embedding(y_vocab_size, latent_dim,trainable=True) \n",
    "dec_emb = dec_emb_layer(decoder_inputs) \n",
    "\n",
    "# LSTM using encoder_states as initial state\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
    "\n",
    "# Attention Layer\n",
    "attn_layer = AttentionLayer(name='attention_layer') \n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
    "\n",
    "# Concat attention output and decoder LSTM output \n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# Dense layer\n",
    "decoder_dense = TimeDistributed(Dense(y_vocab_size, activation='softmax')) \n",
    "decoder_outputs = decoder_dense(decoder_concat_input) \n",
    "\n",
    "# Model Definition\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gvBdWresX4yR"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ADAInMJTX7A_"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "colab_type": "code",
    "id": "c-6VW0p2X9iN",
    "outputId": "3860bfee-c17f-41f6-f3ed-396f8726722d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-136502d92dc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2417\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2772\u001b[0m           \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2773\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 2774\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2704\u001b[0m         relaxed_arg_shapes)\n\u001b[1;32m   2705\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 2706\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   2707\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    <ipython-input-20-f77bd7cfbe90>:106 call  *\n        last_out, e_outputs, _ = K.rnn(\n    /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3104 rnn  *\n        reachable = tf_utils.get_reachable_from_inputs([learning_phase()],\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py:140 get_reachable_from_inputs  **\n        raise TypeError('Expected Operation, Variable, or Tensor, got ' + str(x))\n\n    TypeError: Expected Operation, Variable, or Tensor, got 0\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([x_train,y_train[:,:-1]], y_train.reshape(y_train.shape[0], y_train.shape[1], 1)[:,1:], epochs=30, callbacks=[es], batch_size=128, validation_data=([x_test,y_test[:,:-1]], y_test.reshape(y_test.shape[0],y_test.shape[1], 1)[:,1:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0ThmAJmJYCVd"
   },
   "outputs": [],
   "source": [
    "model.save('/content/drive/My Drive/NLP Project/Project Final/model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tbOxpRf8YEwM"
   },
   "outputs": [],
   "source": [
    "# Visualizing training ans test loss functions\n",
    "\n",
    "\n",
    "from matplotlib import pyplot \n",
    "pyplot.plot(history.history['loss'], label='train') \n",
    "pyplot.plot(history.history['val_loss'], label='test') \n",
    "pyplot.legend() \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9yqFK5YaYHK3"
   },
   "outputs": [],
   "source": [
    "reverse_target_word_index=y_tok.index_word \n",
    "reverse_source_word_index=x_tok.index_word \n",
    "target_word_index=y_tok.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c2XZJiplYJtx"
   },
   "outputs": [],
   "source": [
    "# Encoder Inference\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder Inference\n",
    "# Below tensors hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_len_body,latent_dim))\n",
    "\n",
    "# Getting decoder sequence embeddings\n",
    "dec_emb2= dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# Predicting the next word in the sequence\n",
    "# Setting the initial states to the previous time step states\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "# Attention Inference\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# Dense softmax layer to calculate probability distribution over target vocab\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
    "\n",
    "# Final Decoder model\n",
    "decoder_model = Model(\n",
    "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "[decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hXxr6YgIYOY-"
   },
   "outputs": [],
   "source": [
    "# Function to implement inference\n",
    "\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encoding input as state vectors\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generating empty target sequence of length 1\n",
    "    target_seq = np.zeros((1,1))\n",
    "\n",
    "    # Taking the 'start' word as the first word of the target sequence\n",
    "    target_seq[0, 0] = target_word_index['start']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        try:\n",
    "            sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        except:\n",
    "            sampled_token = reverse_target_word_index[np.random.randint(1, len(reverse_target_word_index))]\n",
    "        if(sampled_token!='end'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "            # Exit condition: either hit max length or find stop word.\n",
    "            if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_len_highlight-1)):\n",
    "                stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IqsSDZ3mYTGM"
   },
   "outputs": [],
   "source": [
    "def seq2highlights(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n",
    "        newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o-9tALmiYWKx"
   },
   "outputs": [],
   "source": [
    "reference = []\n",
    "hypothesis = []\n",
    "for i in range(10):\n",
    "  print(\"Highlights:\")\n",
    "  print(seq2summary(y_test[i]))\n",
    "  reference.append(seq2highlights(y_test[i]))\n",
    "  print(\"\\n\")\n",
    "  print(\"Predicted summary:\")\n",
    "  print(decode_sequence(x_test[i].reshape(1,max_len_body)))\n",
    "  hypothesis.append(decode_sequence(x_test[i].reshape(1,max_len_body)))\n",
    "  print(\"\\n\")\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WtZGcwjrYZ-a"
   },
   "outputs": [],
   "source": [
    "! pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jGmZxS3zYd_P"
   },
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "score = Rouge()\n",
    "score.get_scores(hypothesis, reference, avg = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K4LT351hYmLk"
   },
   "outputs": [],
   "source": [
    "# Reading papers, cleaning, creating & pickling dataframe\n",
    "\n",
    "\n",
    "def read_paper(path):\n",
    "  \"\"\"\n",
    "  Reads research papers and store them in a string\n",
    "  \"\"\"\n",
    "  f = open(path, 'r', encoding=\"utf-8\")\n",
    "  text = str(f.read())\n",
    "  f.close()\n",
    "  return text\n",
    "\n",
    "\n",
    "def create_dataframe(NO_INPUT_PAPERS):\n",
    "  \"\"\"\n",
    "  Takes number of papers to read and stores data in a dataframe\n",
    "  \"\"\"\n",
    "  temp_papers = []\n",
    "  filenames = []\n",
    "  for filename in tqdm(glob.glob(\"/content/drive/My Drive/NLP Project/Project Final/Parsed_Papers/*.txt\")[:NO_INPUT_PAPERS]):\n",
    "      temp_papers.append(read_paper(filename))\n",
    "      filenames.append(filename)\n",
    "  return pd.DataFrame(list(zip(temp_papers, filenames)), columns =['text', 'filenames'])\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "  \"\"\"\n",
    "  Removes unwanted characters, accounting for unicode characters\n",
    "  \"\"\"\n",
    "  text = re.sub(\"@&#\", \" \", text)\n",
    "  text = re.sub(\"\\n\", \" \", text)\n",
    "  text = (text.encode('ascii', 'ignore')).decode(\"utf-8\")\n",
    "  return text\n",
    "\n",
    "\n",
    "data = create_dataframe(NO_INPUT_PAPERS = 10000)\n",
    "\n",
    "data['highlights'] = data['text'].progress_apply(lambda x: re.findall(r'HIGHLIGHTS(.*?)KEYPHRASES', x,  flags = re.I)[0])\n",
    "data = data[data.highlights != '    ']\n",
    "\n",
    "data['body'] = data['text'].progress_apply(lambda x: re.findall(r'.*(?:abstract )(.*?)$', x,  flags = re.I)[0])\n",
    "\n",
    "data.to_pickle(\"./papers.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SlJbYJiSY1xp"
   },
   "outputs": [],
   "source": [
    "# Function to find filename which don't have \"highlights\" in it\n",
    "\n",
    "\n",
    "def file_name(NO_INPUT_PAPERS):\n",
    "  temp_papers = []\n",
    "  for filename in glob.glob(\"/content/drive/My Drive/NLP Project/Project Final/Parsed_Papers/*.txt\")[:NO_INPUT_PAPERS]:\n",
    "    text = read_paper(filename)\n",
    "    text = re.sub(\"@&#\", \" \", text)\n",
    "    text = re.sub(\"\\n\", \" \", text)\n",
    "    text = (text.encode('ascii', 'ignore')).decode(\"utf-8\")\n",
    "    highlights = re.findall(r'HIGHLIGHTS(.*?)KEYPHRASES', text,  flags = re.I)\n",
    "    if highlights == []:\n",
    "      print(filename)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Abstract Generator PreProcessing",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
